# AI
## ICML 2023
- Theoretical Behavior of XAI Methods in the Presence of Suppressor Variables (https://icml.cc/virtual/2023/poster/23521)
- Explainability as statistical inference
- Explainable Data-Driven Optimization: From Context to Decision and Back Again
- NA2Q: Neural Attention Additive Model for Interpretable Multi-Agent Q-Learning
- Self-Interpretable Time Series Prediction with Counterfactual Explanations
- Dividing and Conquering a BlackBox to a Mixture of Interpretable Models: Route, Interpret, Repeat
- XAI Beyond Classification: Interpretable Neural Clustering
- Identifying Interpretable Subspaces in Image Representations
- Interpretable Neural-Symbolic Concept Reasoning
- Monge, Bregman and Occam: Interpretable Optimal Transport in High-Dimensions with Feature-Sparse Maps
- Trainability, Expressivity and Interpretability in Gated Neural ODEs
- On the Impact of Knowledge Distillation for Model Interpretability
- Improved Algorithms for White-Box Adversarial Streams
## NeurIPS
(2022) Decision Trees with Short Explainable Rules Victor Feitosa Souza, Ferdinando Cicalese, Eduardo Laber, Marco Molinaro
(2022) Explainable Reinforcement Learning via Model Transforms Mira Finkelstein, Nitsan levy, Lucy Liu, Yoav Kolumbus, David C. Parkes, Jeffrey S Rosenschein, Sarah Keren
(2022) What I Cannot Predict, I Do Not Understand: A Human-Centered Evaluation Framework for Explainability Methods Julien Colin, Thomas FEL, Remi Cadene, Thomas Serre
(2022) Explaining Preferences with Shapley Values Robert Hu, Siu Lun Chau, Jaime Ferrando Huertas, Dino Sejdinovic
(2022) AttCAT: Explaining Transformers via Attentive Class Activation Tokens Yao Qiang, Deng Pan, Chengyin Li, Xin Li, Rhongho Jang, Dongxiao Zhu
(2022) Estimating and Explaining Model Performance When Both Covariates and Labels Shift Lingjiao Chen, Matei Zaharia, James Y. Zou
(2022) Inherently Explainable Reinforcement Learning in Natural Language Xiangyu Peng, Mark Riedl, Prithviraj Ammanabrolu
(2022) Explainability Via Causal Self-Talk Nicholas A. Roy, Junkyung Kim, Neil Rabinowitz
(2022) Structured Recognition for Generative Models with Explaining Away Changmin Yu, Hugo Soulat, Neil Burgess, Maneesh Sahani
(2022) Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering Pan Lu, Swaroop Mishra, Tanglin Xia, Liang Qiu, Kai-Wei Chang, Song-Chun Zhu, Oyvind Tafjord, Peter Clark, Ashwin Kalyan
(2022) ProtoX: Explaining a Reinforcement Learning Agent via Prototyping Ronilo Ragodos, Tong Wang, Qihang Lin, Xun Zhou
(2022) Self-explaining deep models with logic rule reasoning Seungeon Lee, Xiting Wang, Sungwon Han, Xiaoyuan Yi, Xing Xie, Meeyoung Cha
(2022) Debugging and Explaining Metric Learning Approaches: An Influence Function Based Perspective Ruofan Liu, Yun Lin, XIANGLIN YANG, Jin Song Dong
(2022) Consistent Sufficient Explanations and Minimal Local Rules for explaining the decision of any classifier or regressor Salim I. Amoukou, Nicolas Brunel
(2022) PAC-Bayes Compression Bounds So Tight That They Can Explain Generalization Sanae Lotfi, Marc Finzi, Sanyam Kapoor, Andres Potapczynski, Micah Goldblum, Andrew G. Wilson
(2022) GStarX: Explaining Graph Neural Networks with Structure-Aware Cooperative Games Shichang Zhang, Yozen Liu, Neil Shah, Yizhou Sun
(2022) Where do Models go Wrong? Parameter-Space Saliency Maps for Explainability Roman Levin, Manli Shu, Eitan Borgnia, Furong Huang, Micah Goldblum, Tom Goldstein
(2022) Self-Explaining Deviations for Coordination Hengyuan Hu, Samuel Sokota, David Wu, Anton Bakhtin, Andrei Lupu, Brandon Cui, Jakob Foerster
(2022) ProtoVAE: A Trustworthy Self-Explainable Prototypical Variational Model Srishti Gautam, Ahcène Boubekki, Stine Hansen, Suaiba Salahuddin, Robert Jenssen, Marina Höhne, Michael Kampffmeyer
(2022) Concept Embedding Models: Beyond the Accuracy-Explainability Trade-Off Mateo Espinosa Zarlenga, Pietro Barbiero, Gabriele Ciravegna, Giuseppe Marra, Francesco Giannini, Michelangelo Diligenti, Zohreh Shams, Frederic Precioso, Stefano Melacci, Adrian Weller, Pietro Lió, Mateja Jamnik
(2022) Explain My Surprise: Learning Efficient Long-Term Memory by predicting uncertain outcomes Artyom Sorokin, Nazar Buzun, Leonid Pugachev, Mikhail Burtsev
(2021) Explaining Latent Representations with a Corpus of Examples Jonathan Crabbe, Zhaozhi Qian, Fergus Imrie, Mihaela van der Schaar
(2021) Towards Multi-Grained Explainability for Graph Neural Networks Xiang Wang, Yingxin Wu, An Zhang, Xiangnan He, Tat-Seng Chua
(2021) Nearly-Tight and Oblivious Algorithms for Explainable Clustering Buddhima Gamlath, Xinrui Jia, Adam Polak, Ola Svensson
(2021) Explaining heterogeneity in medial entorhinal cortex with task-driven neural networks Aran Nayebi, Alexander Attinger, Malcolm Campbell, Kiah Hardcastle, Isabel Low, Caitlin S Mallory, Gabriel Mel, Ben Sorscher, Alex H Williams, Surya Ganguli, Lisa Giocomo, Dan Yamins
(2021) Explaining Hyperparameter Optimization via Partial Dependence Plots Julia Moosbauer, Julia Herbinger, Giuseppe Casalicchio, Marius Lindauer, Bernd Bischl
(2021) Learning Theory Can (Sometimes) Explain Generalisation in Graph Neural Networks Pascal Esser, Leena Chennuru Vankadara, Debarghya Ghoshdastidar
(2021) Explainable Semantic Space by Grounding Language to Vision with Cross-Modal Contrastive Learning Yizhen Zhang, Minkyu Choi, Kuan Han, Zhongming Liu
(2021) Reliable Post hoc Explanations: Modeling Uncertainty in Explainability Dylan Slack, Anna Hilgard, Sameer Singh, Himabindu Lakkaraju
(2021) The Out-of-Distribution Problem in Explainability and Search Methods for Feature Importance Explanations Peter Hase, Harry Xie, Mohit Bansal
(2021) Influence Patterns for Explaining Information Flow in BERT Kaiji Lu, Zifan Wang, Piotr Mardziel, Anupam Datta
(2021) Reinforcement Learning Enhanced Explainer for Graph Neural Networks Caihua Shan, Yifei Shen, Yao Zhang, Xiang Li, Dongsheng Li
(2021) EDGE: Explaining Deep Reinforcement Learning Policies Wenbo Guo, Xian Wu, Usmann Khan, Xinyu Xing
(2021) The Utility of Explainable AI in Ad Hoc Human-Machine Teaming Rohan Paleja, Muyleng Ghuy, Nadun Ranawaka Arachchige, Reed Jensen, Matthew Gombolay
(2020) Implicit Regularization in Deep Learning May Not Be Explainable by Norms Noam Razin, Nadav Cohen
(2020) Parameterized Explainer for Graph Neural Network Dongsheng Luo, Wei Cheng, Dongkuan Xu, Wenchao Yu, Bo Zong, Haifeng Chen, Xiang Zhang
(2020) PGM-Explainer: Probabilistic Graphical Model Explanations for Graph Neural Networks Minh Vu, My T. Thai
(2020) Can Implicit Bias Explain Generalization? Stochastic Convex Optimization as a Case Study Assaf Dauber, Meir Feder, Tomer Koren, Roi Livni
(2020) Asymmetric Shapley values: incorporating causal knowledge into model-agnostic explainability Christopher Frye, Colin Rowat, Ilya Feige
(2020) How Can I Explain This to You? An Empirical Study of Deep Neural Network Explanation Methods Jeya Vikranth Jeyakumar, Joseph Noor, Yu-Hsi Cheng, Luis Garcia, Mani Srivastava
(2020) Explainable Voting Dominik Peters, Ariel D. Procaccia, Alexandros Psomas, Zixin Zhou
(2020) What Did You Think Would Happen? Explaining Agent Behaviour through Intended Outcomes Herman Yau, Chris Russell, Simon Hadfield
(2020) Margins are Insufficient for Explaining Gradient Boosting Allan Grønlund, Lior Kamma, Kasper Green Larsen
(2020) Explaining Naive Bayes and Other Linear Classifiers with Polynomial Time and Delay Joao Marques-Silva, Thomas Gerspacher, Martin Cooper, Alexey Ignatiev, Nina Narodytska
(2020) Causal Shapley Values: Exploiting Causal Knowledge to Explain Individual Predictions of Complex Models Tom Heskes, Evi Sijben, Ioan Gabriel Bucur, Tom Claassen
(2019) Uniform convergence may be unable to explain generalization in deep learning Vaishnavh Nagarajan, J. Zico Kolter
(2019) Towards Explaining the Regularization Effect of Initial Large Learning Rate in Training Neural Networks Yuanzhi Li, Colin Wei, Tengyu Ma
(2019) Explaining Landscape Connectivity of Low-cost Solutions for Multilayer Nets Rohith Kuditipudi, Xiang Wang, Holden Lee, Yi Zhang, Zhiyuan Li, Wei Hu, Rong Ge, Sanjeev Arora
(2018) Explaining Deep Learning Models -- A Bayesian Non-parametric Approach Wenbo Guo, Sui Huang, Yunzhe Tao, Xinyu Xing, Lin Lin
(2018) Towards Robust Interpretability with Self-Explaining Neural Networks David Alvarez Melis, Tommi Jaakkola
(2018) Representer Point Selection for Explaining Deep Neural Networks Chih-Kuan Yeh, Joon Kim, Ian En-Hsu Yen, Pradeep K. Ravikumar
## AAAI
## ICLR
## IJCAI
## KDD
# HCI
## CHI
## IUI
## CSCW
