# AI
## ICML 2023
- Theoretical Behavior of XAI Methods in the Presence of Suppressor Variables (https://icml.cc/virtual/2023/poster/23521)
- Explainability as statistical inference
- Explainable Data-Driven Optimization: From Context to Decision and Back Again
- NA2Q: Neural Attention Additive Model for Interpretable Multi-Agent Q-Learning
- Self-Interpretable Time Series Prediction with Counterfactual Explanations
- Dividing and Conquering a BlackBox to a Mixture of Interpretable Models: Route, Interpret, Repeat
- XAI Beyond Classification: Interpretable Neural Clustering
- Identifying Interpretable Subspaces in Image Representations
- Interpretable Neural-Symbolic Concept Reasoning
- Monge, Bregman and Occam: Interpretable Optimal Transport in High-Dimensions with Feature-Sparse Maps
- Trainability, Expressivity and Interpretability in Gated Neural ODEs
- On the Impact of Knowledge Distillation for Model Interpretability
- Improved Algorithms for White-Box Adversarial Streams
